{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bellman.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmEMRqAEhnhP9Ozj0FLILS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krmonline/ReinforcementLearning/blob/main/bellman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imjDTI3YiJ8O"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class Env:\n",
        "    def __init__(self):\n",
        "        self.height = 5\n",
        "        self.width = 5\n",
        "        self.posX = 0\n",
        "        self.posY = 0\n",
        "        self.endX = self.width-1\n",
        "        self.endY = self.height-1\n",
        "        self.actions = [0, 1, 2, 3]\n",
        "        self.stateCount = self.height*self.width\n",
        "        self.actionCount = len(self.actions)\n",
        "\n",
        "    def reset(self):\n",
        "        self.posX = 0\n",
        "        self.posY = 0\n",
        "        self.done = False\n",
        "        return 0, 0, False\n",
        "\n",
        "    # take action\n",
        "    def step(self, action):\n",
        "        if action == 0: # left\n",
        "            self.posX = self.posX-1 if self.posX > 0 else self.posX\n",
        "        if action == 1: # right\n",
        "            self.posX = self.posX+1 if self.posX < self.width - 1 else self.posX\n",
        "        if action == 2: # up\n",
        "            self.posY = self.posY-1 if self.posY > 0 else self.posY\n",
        "        if action == 3: # down\n",
        "            self.posY = self.posY+1 if self.posY < self.height - 1 else self.posY\n",
        "\n",
        "        done = self.posX == self.endX and self.posY == self.endY\n",
        "        # mapping (x,y) position to number between 0 and 5x5-1=24\n",
        "        nextState = self.width * self.posY + self.posX\n",
        "        reward = 1 if done else 0\n",
        "        return nextState, reward, done\n",
        "\n",
        "    # return a random action\n",
        "    def randomAction(self):\n",
        "        return np.random.choice(self.actions)\n",
        "\n",
        "    # display environment\n",
        "    def render(self):\n",
        "        for i in range(self.height):\n",
        "            for j in range(self.width):\n",
        "                if self.posY == i and self.posX == j:\n",
        "                    print(\"O\", end='')\n",
        "                elif self.endY == i and self.endX == j:\n",
        "                    print(\"T\", end='')\n",
        "                else:\n",
        "                    print(\".\", end='')\n",
        "            print(\"\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuq9U6R-pBdX",
        "outputId": "4b5feb1c-a643-45f2-e96f-34cfb4dabf0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "env = Env()\n",
        "\n",
        "env.render()\n",
        "env.step(1)\n",
        "print(\"============\")\n",
        "env.render()\n",
        "env.step(1)\n",
        "print(\"============\")\n",
        "env.render()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            "....T\n",
            "============\n",
            ".O...\n",
            ".....\n",
            ".....\n",
            ".....\n",
            "....T\n",
            "============\n",
            "..O..\n",
            ".....\n",
            ".....\n",
            ".....\n",
            "....T\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOxKwr-OiLsL"
      },
      "source": [
        "#import Env\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "# create environment\n",
        "env = Env()\n",
        "\n",
        "# QTable : contains the Q-Values for every (state,action) pair\n",
        "#qtable = np.random.rand(env.stateCount, env.actionCount).tolist()\n",
        "qtable =  np.zeros((25,4)).tolist()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hsw2donrnpT"
      },
      "source": [
        "# hyperparameters\n",
        "epochs = 1\n",
        "gamma = 0.1\n",
        "epsilon = 0.08\n",
        "decay = 0.1\n",
        "\n",
        "# training loop\n",
        "for i in range(epochs):\n",
        "    state, reward, done = env.reset()\n",
        "    steps = 0\n",
        "\n",
        "    while not done:\n",
        "        os.system('clear')\n",
        "        #print(\"epoch #\", i+1, \"/\", epochs)\n",
        "        #env.render()\n",
        "        #time.sleep(0.05)\n",
        "\n",
        "        # count steps to finish game\n",
        "        steps += 1\n",
        "\n",
        "        # act randomly sometimes to allow exploration\n",
        "        if np.random.uniform() < epsilon:\n",
        "            action = env.randomAction()\n",
        "        # if not select max action in Qtable (act greedy)\n",
        "        else:\n",
        "            action = qtable[state].index(max(qtable[state]))\n",
        "\n",
        "        # take action\n",
        "        next_state, reward, done = env.step(action)\n",
        "\n",
        "        # update qtable value with Bellman equation\n",
        "        qtable[state][action] = reward + gamma * max(qtable[next_state])\n",
        "\n",
        "        # update state\n",
        "        state = next_state\n",
        "    # The more we learn, the less we take random actions\n",
        "    epsilon -= decay*epsilon\n",
        "\n",
        "    print(\"\\nDone in\", steps, \"steps\".format(steps))\n",
        "    time.sleep(0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol6GFDhviT1Y",
        "outputId": "d7639a6c-5c6d-4fbf-ae6e-8aed5bd9b119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "            action = qtable[state].index(max(qtable[state]))\n",
        "\n",
        "        # take action\n",
        "        next_state, reward, done = env.step(action)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.77123414e-06, 1.93759287e-05, 5.00849117e-05, 5.00849117e-05],\n",
              "       [6.42315702e-06, 1.81386395e-04, 6.35394962e-05, 1.38405238e-04],\n",
              "       [6.35394962e-04, 9.09225398e-04, 6.79507711e-04, 8.77344516e-04],\n",
              "       [9.09225398e-05, 9.28747283e-04, 9.09225398e-04, 9.09225398e-04],\n",
              "       [1.81386395e-04, 9.28747283e-05, 1.81386395e-04, 7.42940387e-04],\n",
              "       [7.79694360e-05, 4.69745996e-04, 6.35394962e-06, 8.26154819e-05],\n",
              "       [9.39619828e-05, 8.90508305e-04, 7.58716056e-04, 7.34788945e-04],\n",
              "       [7.71200763e-04, 2.37792634e-03, 6.64681373e-03, 9.82784227e-04],\n",
              "       [7.94323843e-04, 5.93195177e-04, 4.13165105e-04, 2.84165770e-03],\n",
              "       [7.82743910e-04, 7.82743910e-04, 1.81386395e-04, 4.48353617e-03],\n",
              "       [4.69745996e-04, 7.79694360e-04, 7.79694360e-05, 5.30173413e-04],\n",
              "       [4.69745996e-04, 6.26775040e-03, 6.42315702e-04, 1.08878800e-04],\n",
              "       [1.93759287e-03, 2.94128600e-03, 4.39552286e-03, 2.45049909e-03],\n",
              "       [1.91067096e-03, 6.47100462e-03, 9.75481223e-04, 1.08878800e-02],\n",
              "       [2.40957807e-03, 1.69261748e-02, 9.11895336e-03, 2.13116746e-02],\n",
              "       [8.26154819e-04, 4.84173311e-04, 9.21330579e-04, 3.78070088e-04],\n",
              "       [6.32692255e-04, 1.08878800e-03, 9.40575674e-04, 9.82784227e-04],\n",
              "       [8.35809525e-04, 1.08878800e-02, 4.17214373e-03, 1.08878800e-02],\n",
              "       [2.85917722e-03, 1.08878800e-01, 6.83979594e-03, 7.66188862e-02],\n",
              "       [2.37978659e-02, 5.93195177e-02, 7.03232264e-02, 1.08878800e+00],\n",
              "       [1.98454512e-03, 1.57437455e-03, 8.96892740e-04, 8.35809525e-04],\n",
              "       [1.98454512e-03, 1.08878800e-02, 6.93471173e-04, 6.32692255e-03],\n",
              "       [6.93471173e-03, 1.08878800e-01, 6.26775040e-02, 9.82784227e-03],\n",
              "       [8.69726737e-02, 1.08878800e+00, 4.80765595e-01, 6.91344789e-02],\n",
              "       [6.76338234e-01, 4.53560672e-01, 4.18866540e-01, 8.87879971e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrHqZ8W8iv97",
        "outputId": "07852673-0f80-424b-8daa-1198e44e2c9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "done = False\n",
        "env.reset()\n",
        "while not done:\n",
        "        print(\"======\")\n",
        "        env.render()\n",
        "        time.sleep(0.05)\n",
        "        steps += 1\n",
        "        action = qtable[state].index(max(qtable[state]))\n",
        "        # take action\n",
        "        next_state, reward, done = env.step(action)\n",
        "        # update state\n",
        "        state = next_state"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======\n",
            "O....\n",
            ".....\n",
            ".....\n",
            ".....\n",
            "....T\n",
            "======\n",
            ".O...\n",
            ".....\n",
            ".....\n",
            ".....\n",
            "....T\n",
            "======\n",
            "..O..\n",
            ".....\n",
            ".....\n",
            ".....\n",
            "....T\n",
            "======\n",
            "...O.\n",
            ".....\n",
            ".....\n",
            ".....\n",
            "....T\n",
            "======\n",
            ".....\n",
            "...O.\n",
            ".....\n",
            ".....\n",
            "....T\n",
            "======\n",
            ".....\n",
            "....O\n",
            ".....\n",
            ".....\n",
            "....T\n",
            "======\n",
            ".....\n",
            ".....\n",
            "....O\n",
            ".....\n",
            "....T\n",
            "======\n",
            ".....\n",
            ".....\n",
            ".....\n",
            "....O\n",
            "....T\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRzZJM3y-hv6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}